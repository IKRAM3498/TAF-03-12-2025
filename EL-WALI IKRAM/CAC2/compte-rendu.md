**Nom de l'√©tudiant :** EL-WALI IKRAM
**Classe :** 24010354
# Food Nutrition Dataset
---

# Compte rendu

## Analyse Nutritionnelle et Pr√©diction des Calories par R√©gression

**Date :** 3 D√©cembre 2025

---
#La th√©matique choisie pour cette analyse est la sant√©, avec un accent particulier sur l'alimentation et la nutrition.

# √Ä propos du jeu de donn√©es :

#1. S√©lection du jeu de donn√©es
Le jeu de donn√©es s√©lectionn√© est le **Food Nutrition Dataset (150+ Everyday Foods)**, disponible sur la plateforme **Kaggle**.  
Il contient des informations nutritionnelles d√©taill√©es sur plus de **150 aliments couramment consomm√©s**, incluant notamment les calories, les prot√©ines, les glucides, les lipides et d‚Äôautres nutriments essentiels.

Ce dataset est pertinent pour plusieurs raisons :

- Il n'est **pas trivial** (contrairement √† Titanic ou Iris).  
- Il contient principalement des **variables quantitatives exploitables**.  
- Il permet d'√©tudier une th√©matique d'int√©r√™t g√©n√©ral : **la nutrition et la composition des aliments**.  
- Il est propre, structur√© et directement utilisable pour une analyse ou un mod√®le de Machine Learning.

#2. D√©finition de la Probl√©matique (T√¢che : R√©gression)

L‚Äôobjectif de ce projet est de construire un **mod√®le de r√©gression** capable de **pr√©dire le nombre de calories d‚Äôun aliment** √† partir de ses valeurs nutritionnelles (prot√©ines, glucides, lipides, fibres, etc.).

**Il s'agit donc d'une t√¢che de r√©gression**, car la variable cible (**Calories**) est une variable **num√©rique continue**.
Probl√©matique √©tudi√©e :
> **Peut-on pr√©dire de mani√®re fiable la valeur calorique d‚Äôun aliment √† partir de sa composition nutritionnelle ?**
Cette probl√©matique permet :

- d'√©valuer l‚Äôimportance de chaque nutriment dans le total calorique,  
- de tester diff√©rents mod√®les de r√©gression,  
- de v√©rifier la coh√©rence du dataset par rapport aux lois nutritionnelles (ex : calories ‚âà 4√óprot√©ines + 4√óglucides + 9√ólipides).

# 3. Dictionnaire des Donn√©es (Metadata)

## Taille du dataset
- **Nombre de lignes (aliments)** : ‚âà 150  
- **Nombre de colonnes (variables)** : environ 10 √† 20 selon la version

## Types de variables
- **Variables quantitatives continues** : calories, prot√©ines, glucides, lipides, fibres, sucres, sodium‚Ä¶  
- **Variables qualitatives nominales** : nom de l‚Äôaliment, √©ventuellement cat√©gorie de l‚Äôaliment

## Description des variables principales

| Variable | Type | Description |
|---------|------|-------------|
| **Food** | Cat√©gorielle | Nom de l‚Äôaliment (ex : Apple, Rice, Chicken Breast) |
| **Calories** | Num√©rique | √ânergie totale en kcal (üåü *variable cible du mod√®le*) |
| **Protein (g)** | Num√©rique | Quantit√© de prot√©ines (g) |
| **Carbohydrates (g)** | Num√©rique | Quantit√© totale de glucides (g) |
| **Fat (g)** | Num√©rique | Quantit√© totale de lipides (g) |
| **Fiber (g)** | Num√©rique | Teneur en fibres |
| **Sugar (g)** | Num√©rique | Quantit√© de sucres |
| **Sodium (mg)** | Num√©rique | Teneur en sodium (mg) |

## Variable Cible (Target)

La **target** utilis√©e pour la t√¢che de r√©gression est :

 **Calories**

---

## 1. Introduction et Contexte

Ce rapport d√©taille l'analyse et la mod√©lisation pr√©dictive d'un jeu de donn√©es nutritionnel. L'objectif est de pr√©dire les **calories d'un aliment** √† partir de ses autres caract√©ristiques nutritionnelles.

Les √©tapes suivies incluent l'exploration des donn√©es, le pr√©traitement, la cr√©ation de nouvelles features, et la comparaison de trois mod√®les de r√©gression : **Arbre de D√©cision, Random Forest et SVR**.

---

## 2. Analyse Exploratoire des Donn√©es

### 2.1 Chargement et Structure du Dataset

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

# Chargement
df = pd.read_csv("food_nutrition.csv")
print(df.shape)
df.head()
```

* **Observations :** ~150 aliments
* **Variables :** Calories (target), Prot√©ines, Glucides, Lipides, Fibres, Sucres, etc.

### 2. Pr√©-traitement (Preprocessing)
Nettoyage des donn√©es
Gestion des doublons
Formatage des donn√©es
Imputation des valeurs manquantes
Utilisation de strat√©gies avanc√©es
Encodage des variables cat√©gorielles
One-Hot Encoding
Label Encoding
Target Encoding
Normalisation ou Standardisation des donn√©es num√©riques
* Cr√©ation de **ratios nutritionnels** (ex: prot√©ines/calories, lipides/calories) pour am√©liorer la pr√©diction.
* Encodage des variables cat√©gorielles (ex: type d‚Äôaliment).
* Normalisation pour les mod√®les sensibles √† l‚Äô√©chelle (SVR).

```python
# Informations g√©n√©rales sur le dataset
df.info()

# Statistiques descriptives des colonnes num√©riques
df.describe()

# V√©rification de la pr√©sence de valeurs manquantes
df.isnull().sum()

# V√©rification des doublons
print("Nombre de doublons :", df.duplicated().sum())
# Supprimer les doublons si pr√©sents
df = df.drop_duplicates()
print("Nombre de lignes apr√®s suppression des doublons :", df.shape[0])

# S√©lection uniquement des colonnes num√©riques pour l'imputation
numeric_cols = df.select_dtypes(include=np.number).columns

# KNNImputer : remplit les valeurs manquantes en fonction des k voisins les plus proches
imputer = KNNImputer(n_neighbors=5)
df[numeric_cols] = imputer.fit_transform(df[numeric_cols])

# V√©rification apr√®s imputation
df.isnull().sum()

# V√©rification des types de colonnes
df.dtypes

# Conversion des colonnes num√©riques en float (si besoin)
for col in numeric_cols:
    df[col] = df[col].astype(float)

# Supprimer colonnes inutiles si n√©cessaire (ex : ID)
if 'ID' in df.columns:
    df.drop('ID', axis=1, inplace=True)
```

**Interpr√©tation :**  Le pr√©-traitement permet de pr√©parer les donn√©es pour la mod√©lisation. Il inclut le nettoyage, la suppression des doublons, la correction des formats et l‚Äôimputation des valeurs manquantes. Les variables cat√©gorielles sont transform√©es en nombres via des encodages (One-Hot, Label ou Target Encoding), et les donn√©es num√©riques sont normalis√©es ou standardis√©es pour garantir que tous les mod√®les puissent apprendre efficacement et produire des pr√©dictions fiables.



### 2. Analyse Exploratoire des Donn√©es (EDA)
##2.1. Distribution des variables num√©riques
<img width="1492" height="690" alt="image" src="https://github.com/user-attachments/assets/ea95d0a4-e2b3-4f1a-bb61-1d0bc74b6365" />
* Histogrammes des calories, prot√©ines, lipides et glucides.

**Interpr√©tation :** Cette figure montre la distribution de six variables nutritionnelles (calories, prot√©ines, glucides, lipides, fer, vitamine C) sous forme d‚Äôhistogrammes avec une courbe de densit√© liss√©e pour chacune.

## Forme g√©n√©rale des distributions  
Les six graphiques pr√©sentent tous une forte asym√©trie √† droite‚ÄØ: la majorit√© des valeurs est faible, avec quelques valeurs tr√®s √©lev√©es qui tirent la queue de la distribution vers la droite.  
Cela sugg√®re que la plupart des aliments de l‚Äô√©chantillon sont relativement ¬´‚ÄØpauvres‚ÄØ¬ª dans chaque nutriment, et qu‚Äôun petit nombre d‚Äôaliments concentrent des teneurs beaucoup plus √©lev√©es.

## D√©tails par variable  
- Calories et prot√©ines : distributions concentr√©es sur des valeurs faibles, avec quelques aliments beaucoup plus caloriques et prot√©in√©s (queue longue).  
- Glucides (carbs) : distribution un peu plus √©tal√©e, montrant une diversit√© plus importante des teneurs en glucides entre les aliments.  
- Lipides (fat) : tr√®s forte concentration pr√®s de z√©ro, ce qui indique que la majorit√© des aliments sont peu gras, mais certains sont extr√™mement riches en lipides.  
- Fer et vitamine C : m√™me structure fortement dissym√©trique, typique de micronutriments o√π quelques aliments (par ex. abats, certains l√©gumes/fruits) sont tr√®s riches tandis que la plupart en contiennent peu.

## Ce que cela implique pour l‚Äôanalyse  
- Les distributions non normales et tr√®s asym√©triques rendent l‚Äôusage de la moyenne et de l‚Äô√©cart‚Äëtype moins informatifs que la m√©diane et les quantiles.  
- Des transformations (par exemple logarithme) ou des m√©thodes non param√©triques peuvent √™tre pr√©f√©rables pour mod√©liser ou comparer ces variables.  
- Les longues queues droites indiquent la pr√©sence potentielle de valeurs extr√™mes qu‚Äôil faudra examiner s√©par√©ment pour comprendre quels aliments les produisent et si ce sont des outliers √† traiter ou des cas typiques mais rares.

##2.2. Boxplots pour d√©tecter les outliers
<img width="1489" height="667" alt="image" src="https://github.com/user-attachments/assets/da5490a9-137f-4b2f-9509-47ae32d57a2a" />
**interpritation:** Ces six boxplots r√©sument la r√©partition des m√™mes variables nutritionnelles (calories, prot√©ines, glucides, lipides, fer, vitamine C) en mettant l‚Äôaccent sur la m√©diane, la dispersion et les valeurs extr√™mes.

## Information donn√©e par les boxplots  
- La bo√Æte repr√©sente l‚Äôintervalle interquartile (du 1er au 3e quartile), donc la zone o√π se trouvent 50% des observations.  
- La ligne √† l‚Äôint√©rieur de chaque bo√Æte est la m√©diane‚ÄØ: elle indique le niveau ¬´‚ÄØtypique‚ÄØ¬ª de chaque nutriment.  
- Les ¬´ moustaches ¬ª prolongent la bo√Æte jusqu‚Äô√† des valeurs encore consid√©r√©es comme normales, et les points isol√©s au‚Äëdel√† sont des valeurs aberrantes (outliers), beaucoup plus √©lev√©es que le reste des donn√©es.

## Ce que l‚Äôon observe pour ces nutriments  
- Pour toutes les variables, la m√©diane est proche de la partie basse de la bo√Æte et tr√®s pr√®s de z√©ro, ce qui confirme que la majorit√© des aliments sont peu riches dans chaque nutriment, avec quelques aliments beaucoup plus riches.  
- Le grand nombre de points au‚Äëdessus des moustaches montre de nombreux outliers √† haute teneur (aliments tr√®s caloriques, tr√®s gras, tr√®s riches en fer ou en vitamine C, etc.), ce qui traduit des distributions tr√®s asym√©triques et h√©t√©rog√®nes.

## Implications statistiques et pratiques  
- La pr√©sence de nombreux outliers indique qu‚Äôil faut √™tre prudent avec la moyenne‚ÄØ: elle sera fortement tir√©e vers le haut et ne repr√©sentera pas bien l‚Äô¬´ aliment moyen ¬ª.  
- Pour comparer des groupes d‚Äôaliments ou construire des mod√®les, il peut √™tre pertinent d‚Äôutiliser la m√©diane, des tests non param√©triques ou d‚Äô√©ventuelles transformations (par exemple logarithmiques) pour r√©duire l‚Äôinfluence de ces valeurs extr√™mes.

## 2.3. Heatmap des corr√©lations
<img width="1319" height="1245" alt="image" src="https://github.com/user-attachments/assets/09e669c5-1da0-4759-851c-66d26a158935" />
**interpritation:** Analyse de la Carte de Chaleur
Objectif : Cette carte de chaleur vise √† visualiser les coefficients de corr√©lation (g√©n√©ralement la corr√©lation de Pearson, mais d'autres peuvent √™tre utilis√©s) entre diff√©rentes variables.

Variables : Les variables sont list√©es √† la fois sur l'axe vertical (lignes) et l'axe horizontal (colonnes). Elles semblent repr√©senter des produits alimentaires sp√©cifiques (food_name: ...) ou des cat√©gories alimentaires (category: ...).

Code de Couleurs (L√©gende √† Droite) :

Rouge Vif (Proche de +1.0) : Indique une forte corr√©lation positive. Lorsque la valeur d'une variable augmente, la valeur de l'autre variable a tendance √† augmenter aussi.

Bleu Fonc√© (Proche de -1.0) : Indique une forte corr√©lation n√©gative. Lorsque la valeur d'une variable augmente, la valeur de l'autre variable a tendance √† diminuer.

Blanc (Proche de 0.0) : Indique une absence de corr√©lation ou une corr√©lation tr√®s faible.

(Dans ce graphique, on voit des valeurs allant de -0.2 √† 1.0).

Lecture du Graphique (Observations) :

Matrice Sym√©trique : C'est une matrice de corr√©lation compl√®te. La moiti√© sup√©rieure est la sym√©trie de la moiti√© inf√©rieure.

Diagonale (Non Visiblement Remplie) : La diagonale principale (l√† o√π une variable est corr√©l√©e avec elle-m√™me) devrait √™tre de 1.0 (rouge vif), mais la matrice semble avoir √©t√© tronqu√©e ou les variables sont r√©ordonn√©es/filtr√©es de mani√®re sp√©cifique.

Distribution des Valeurs : La grande majorit√© de la carte est blanche ou noire, ce qui signifie que la plupart des paires de produits/cat√©gories n'ont pas de corr√©lation significative les unes avec les autres.

Points de Corr√©lation Significative :

Il y a quelques points blancs/noirs intenses qui pourraient repr√©senter des corr√©lations tr√®s proches de 1.0 (ou -0.2). Par exemple, il semble y avoir des groupes de corr√©lations positives fortes (petits carr√©s rouges/noirs) dans la partie sup√©rieure droite et autour du centre du graphique. Ces points indiquent des associations claires entre certains aliments.

Exemple (hypoth√©tique) : Si la case entre food_name: Bacon and tomato dressing et food_name: Coleslaw est rouge, cela pourrait signifier que si l'un est consomm√© ou achet√©, l'autre l'est aussi fr√©quemment.

Les corr√©lations n√©gatives (bleu) semblent √™tre rares ou inexistantes dans la partie visible, la plage commen√ßant √† -0.2 (bleu tr√®s clair).

##2.4. Scatterplots : relation features ‚Üî target
<img width="1489" height="690" alt="image" src="https://github.com/user-attachments/assets/bb0e4cab-6d8b-4914-849f-f81d4afdaeb1" />
**interpritation :** 
**cinq diagrammes de dispersion (scatter plots)** qui explorent la relation entre la **teneur en calories** (Calories, sur l'axe Y) et diff√©rentes composantes nutritionnelles (sur l'axe X) : **prot√©ines, glucides (carbs), lipides (fat), fer (iron) et vitamine C (vitamin_c)**.

Il est tr√®s probable que ces donn√©es aient √©t√© **normalis√©es ou standardis√©es** (car les valeurs sont centr√©es autour de 0 et vont de -1 √† +7 environ, ce qui n'est pas le cas des valeurs nutritionnelles brutes).

###  **Interpr√©tation Rapide des Graphiques**

| Graphique | Relation Observ√©e | Interpr√©tation |
| :--- | :--- | :--- |
| **Protein vs Calories** | Tendance l√©g√®re √† positive. | Plus un aliment est riche en prot√©ines, plus il a tendance √† √™tre calorique. |
| **Carbs vs Calories** | Tendance positive notable. | La teneur en glucides semble √™tre un facteur important de la teneur en calories. |
| **Fat vs Calories** | Tendance positive tr√®s claire. | **Forte corr√©lation positive.** C'est la relation la plus marqu√©e. Les aliments tr√®s gras sont tr√®s souvent les plus caloriques (point √† l'extr√™me droite). |
| **Iron vs Calories** | Tendance positive mod√©r√©e. | Les aliments riches en fer ont tendance √† avoir une teneur en calories plus √©lev√©e. |
| **Vitamin\_C vs Calories** | Pas de tendance positive claire. | **Faible ou absence de corr√©lation.** Les aliments tr√®s riches en vitamine C (points √† droite) peuvent √™tre √† la fois tr√®s peu ou tr√®s caloriques (points √©parpill√©s sur Y). |

---

## 3. M√©thodologie de Mod√©lisation

### 3.1 S√©paration Train/Test

```python
from sklearn.model_selection import train_test_split

y = df['calories']
X = df.drop(columns=['calories'])

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
```

### 3.2 Mod√®les de R√©gression Test√©s

1. LinearRegression
2. RandomForestRegressor
3. XGBRegressor

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor

# Trois mod√®les diff√©rents
models = {
    'Linear Regression': LinearRegression(),
    'Random Forest': RandomForestRegressor(random_state=42),
    'XGBoost': XGBRegressor(random_state=42, eval_metric='rmse')

##1. Scatterplot : R√©el vs. Pr√©dit (Random Forest)
<img width="845" height="547" alt="image" src="https://github.com/user-attachments/assets/e17fa814-5299-4cf3-991d-22ca75fdd203" />

**interpritation :** 
Absolument. Voici une interpr√©tation concise et structur√©e, pr√™te √† √™tre copi√©e-coll√©e :

#### **1. Random Forest : R√©el vs. Pr√©dit (Performance du Mod√®le)**

* Ce graphique √©value la performance d'un mod√®le de pr√©diction (Random Forest) des Calories.
* **Axes :** Calories r√©elles (X) vs. Calories pr√©dites (Y).
* **Ligne Id√©ale ($y=x$) :** La ligne pointill√©e rouge repr√©sente une pr√©diction parfaite.
* **Conclusion :** Le mod√®le est **tr√®s performant**. La majorit√© des points (aliments) sont tr√®s proches de la ligne id√©ale, signifiant une bonne capacit√© √† pr√©dire les calories. Seuls quelques points (ex: vers X=4, Y=1) montrent une sous-estimation significative (erreurs).

#### **2. Comparaison Nutriments vs. Calories (Corr√©lations)**

Ces diagrammes de dispersion montrent la relation entre la teneur en Calories (Y) et cinq nutriments (X).

| Nutriment | Tendance Observ√©e | Impact sur les Calories |
| :--- | :--- | :--- |
| **Fat (Lipides)** | Tr√®s forte tendance positive. | **Meilleur pr√©dicteur.** Les aliments tr√®s gras sont tr√®s caloriques. |
| **Carbs (Glucides)** | Tendance positive notable. | **Bon pr√©dicteur.** Contribue significativement √† la teneur en calories. |
| **Protein (Prot√©ines)** | Tendance positive l√©g√®re. | **Contribution mod√©r√©e** aux calories. |
| **Iron (Fer)** | Tendance positive mod√©r√©e. | Les aliments riches en fer ont tendance √† √™tre plus caloriques. |
| **Vitamin\_C (Vitamine C)** | Faible ou absence de tendance. | **Faible pr√©dicteur.** La teneur en Vitamine C n'est pas li√©e au niveau de calories. |

**Synth√®se :** Les **Lipides (Fat)** et les **Glucides (Carbs)** sont les facteurs d√©terminants de la teneur en calories, ce qui justifie la bonne performance du mod√®le Random Forest.
## 2. Scatterplot : Linear Regression
<img width="845" height="548" alt="image" src="https://github.com/user-attachments/assets/c94a9966-c1b7-4d9e-b6a5-87a26af17dbb" />
**interpritation :** 

#### **1. Relations Nutriments vs. Calories **

* **Fat (Lipides) :** Tr√®s forte corr√©lation positive avec les Calories. **Meilleur pr√©dicteur.**
* **Carbs (Glucides) :** Corr√©lation positive mod√©r√©e √† forte avec les Calories.
* **Protein (Prot√©ines) & Iron (Fer) :** Corr√©lations positives faibles √† mod√©r√©es.
* **Vitamin\_C (Vitamine C) :** Faible ou absence de corr√©lation.

#### **2. Performance des Mod√®les de Pr√©diction (Images 1 & 2)**

Les graphiques comparent les Calories r√©elles (X) et les Calories pr√©dites (Y).

* **Random Forest (Image 2) :**
    * **Performance : Tr√®s bonne.** Les points sont tr√®s proches de la ligne id√©ale ($y=x$).
    * **Conclusion :** Le mod√®le Random Forest est le plus pr√©cis, g√©rant bien la non-lin√©arit√© et les valeurs extr√™mes.
* **Linear Regression (Image 1) :**
    * **Performance : Moins bonne.** Les points sont plus dispers√©s autour de la ligne id√©ale.
    * **Conclusion :** Ce mod√®le est moins pr√©cis, surtout pour les valeurs extr√™mes (ex : la valeur r√©elle la plus √©lev√©e est sous-estim√©e).

**Synth√®se :** Les **Lipides (Fat)** et les **Glucides (Carbs)** sont les facteurs d√©terminants. Le mod√®le **Random Forest** est plus efficace que la R√©gression Lin√©aire pour pr√©dire la teneur en calories.
##3. Scatterplot : XGBoost Regressor
<img width="845" height="547" alt="image" src="https://github.com/user-attachments/assets/b5b838cd-06b6-41d8-ae78-3edf161de860" />
** interpritation :** 

Ce graphique de dispersion √©value la performance du mod√®le de r√©gression **XGBoost** (Extreme Gradient Boosting) pour la pr√©diction de la teneur en calories.

#### **1. Description du Graphique**

* **Titre :** XGBoost : R√©el vs. Pr√©dit.
* **Axe X (horizontal) :** **Calories r√©elles** (valeurs observ√©es dans les donn√©es).
* **Axe Y (vertical) :** **Calories pr√©dites** (valeurs estim√©es par le mod√®le XGBoost).
* **Ligne Id√©ale (Trait Rouge) :** La ligne $y=x$ repr√©sente le sc√©nario de pr√©diction parfaite.

#### **2. Analyse de la Performance**

* **Performance Globale : Tr√®s Bonne.**
    * La grande majorit√© des points bleus sont **tr√®s proches** de la ligne id√©ale rouge, surtout pour les valeurs de calories basses √† moyennes (entre -1 et +2). Cela indique que le mod√®le XGBoost est **tr√®s pr√©cis** dans ses estimations.
* **Analyse des Extr√™mes :**
    * **Valeur R√©elle Maximale (autour de 4.2 sur X) :** Le mod√®le a fait une pr√©diction l√©g√®rement inf√©rieure √† la valeur r√©elle (pr√©dite autour de 1.4 sur Y), montrant une **sous-estimation** dans le cas de l'aliment le plus calorique.
    * **Erreur Notable (autour de X=3.0) :** Il y a un point avec une valeur r√©elle de calories autour de 3.0 qui est **sur-estim√©e** par le mod√®le (pr√©dite autour de 3.8 sur Y). C'est l'erreur la plus visible dans la partie sup√©rieure du graphique.

#### **3. Conclusion**

Le mod√®le **XGBoost** est un **excellent pr√©dicteur des calories** dans ce jeu de donn√©es, d√©montrant une performance largement sup√©rieure pour la majorit√© des observations. Ses erreurs sont concentr√©es sur un petit nombre de valeurs extr√™mes.

###**analyse comparative entre les 3 modeles :**
---
## Analyse Comparative des Mod√®les de Pr√©diction des Calories

La comparaison se base sur la proximit√© des points de pr√©diction (Calories pr√©dites) par rapport √† la ligne id√©ale $y=x$ (Calories r√©elles).

| Crit√®re | Random Forest | XGBoost | R√©gression Lin√©aire |
| :--- | :--- | :--- | :--- |
| **Performance Globale** | **Excellente.** Pr√©cision tr√®s √©lev√©e. | **Excellente.** Tr√®s haute pr√©cision. | **M√©diocre.** Pr√©cision inf√©rieure aux autres. |
| **Dispersion des Points** | **Tr√®s faible.** Les points sont tr√®s serr√©s le long de la ligne id√©ale. | **Faible.** Points tr√®s proches, avec une l√©g√®re dispersion. | **√âlev√©e.** Points dispers√©s, s'√©loignant de la ligne id√©ale. |
| **Gestion de la Non-Lin√©arit√©** | **Tr√®s bonne.** Capacit√© inh√©rente √† mod√©liser des relations complexes. | **Tr√®s bonne.** Excellent traitement des relations non lin√©aires. | **Faible.** Suppose une relation lin√©aire entre les variables, ce qui est une limitation. |
| **Performance sur les Valeurs Extr√™mes** | **Tr√®s bonne.** Pr√©dit avec pr√©cision les valeurs tr√®s faibles et tr√®s √©lev√©es. | **Bonne.** G√®re bien la plupart des extr√™mes, mais montre une **sur-estimation** notable √† $X\approx3.0$ et une **sous-estimation** √† $X\approx4.2$. | **Faible.** Difficult√© √† pr√©dire les valeurs tr√®s √©lev√©es (sous-estimation fr√©quente √† $X>1.0$). |
| **Meilleur Mod√®le** | **Vainqueur (Meilleure coh√©rence globale).** | **Tr√®s Proche du Vainqueur.** | **Moins performant.** |

---

### Conclusion

1.  **Mod√®les Gagnants :** Les mod√®les bas√©s sur les arbres de d√©cision (Random Forest et XGBoost) sont **nettement sup√©rieurs** √† la R√©gression Lin√©aire. Ils sont mieux adapt√©s aux donn√©es de calories qui pr√©sentent des relations complexes (non lin√©aires) avec les nutriments.
2.  **Mod√®le Optimal :** Le **Random Forest** pr√©sente la **meilleure performance globale et la meilleure coh√©rence**, avec la plus faible dispersion des points autour de la ligne id√©ale.
3.  **Facteurs Expliquant la Performance :** La sup√©riorit√© des mod√®les non lin√©aires s'explique par le fait que les **Lipides (Fat)** et les **Glucides (Carbs)**, bien que les plus corr√©l√©s, peuvent avoir des effets non simples qui sont mieux captur√©s par des algorithmes complexes.
---

### **conclusion :**
# Conclusion de l'analyse

Dans ce projet, nous avons travaill√© sur le dataset **Food Nutrition Dataset** pour pr√©dire les **calories** des aliments en fonction de leurs caract√©ristiques nutritionnelles et de leurs cat√©gories.

## √âtapes r√©alis√©es

1. **Pr√©-traitement (Preprocessing)**
   - Nettoyage des donn√©es : gestion des doublons et formatage des colonnes.
   - Imputation des valeurs manquantes pour les variables num√©riques et cat√©gorielles.
   - Encodage des variables cat√©gorielles via One-Hot Encoding.
   - Standardisation des donn√©es num√©riques pour faciliter l'apprentissage des mod√®les.

2. **Analyse exploratoire des donn√©es (EDA)**
   - Visualisation des distributions des variables et des corr√©lations avec la target.
   - Identification des relations importantes entre certaines variables nutritionnelles et les calories.
   - Feature engineering : cr√©ation de nouvelles variables (ratios nutritionnels) pour am√©liorer la pr√©diction.

3. **Mod√©lisation (Machine Learning)**
   - Trois mod√®les de r√©gression ont √©t√© test√©s : 
     - **Linear Regression**
     - **Random Forest Regressor**
     - **XGBoost Regressor**
   - Une validation crois√©e a √©t√© r√©alis√©e pour √©valuer les performances de chaque mod√®le.
   - Le mod√®le **Random Forest** a √©t√© identifi√© comme le plus performant.
   - Optimisation des hyperparam√®tres pour Random Forest et XGBoost afin d'am√©liorer la pr√©cision.

4. **√âvaluation et visualisation**
   - Calcul des m√©triques : RMSE, MAE et R¬≤ pour chaque mod√®le.
   - Scatterplot des calories r√©elles vs. pr√©dites pour le mod√®le Random Forest pour visualiser la qualit√© des pr√©dictions.
   - Analyse de l‚Äôimportance des features :
     - Pour Random Forest et XGBoost : feature_importances_
     - Pour Linear Regression : coefficients des variables (importance bas√©e sur valeur absolue)

## Interpr√©tation finale

- Les mod√®les bas√©s sur des arbres (Random Forest et XGBoost) offrent de meilleures performances pour ce dataset par rapport √† une r√©gression lin√©aire simple, en raison de la complexit√© non lin√©aire des relations entre les variables nutritionnelles et les calories.
- Les ratios nutritionnels cr√©√©s lors du feature engineering ont permis d‚Äôam√©liorer la pr√©diction.
- L‚Äôanalyse des features importantes permet d‚Äôidentifier quelles variables ont le plus d‚Äôimpact sur le calcul des calories, offrant ainsi un aper√ßu utile pour des applications nutritionnelles ou de recommandations alimentaires.

> En r√©sum√©, ce projet illustre une **approche compl√®te de Machine Learning pour la pr√©diction de calories**, depuis le nettoyage des donn√©es jusqu‚Äô√† l‚Äôinterpr√©tation des r√©sultats et l‚Äôanalyse des features les plus influentes.

